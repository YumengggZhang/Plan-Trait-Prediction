{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix ,roc_curve,roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from einops import rearrange\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    train_path = 'input/train.csv'\n",
    "    test_path = 'input/test.csv'\n",
    "    MAX_EPOCH = 200\n",
    "    BATCH_SIZE = 128\n",
    "    weight_decay = 1e-3\n",
    "    LR=0.0001\n",
    "    img_size = 140\n",
    "    sd_features = ['X4_sd', 'X11_sd','X18_sd', 'X26_sd', 'X50_sd', 'X3112_sd']\n",
    "    label_features = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(args.train_path)\n",
    "test_df = pd.read_csv(args.test_path)\n",
    "train_df['id'] = train_df['id'].map(lambda x: args.base_path + '/train_images/' + str(x)+ \".jpeg\")\n",
    "test_df['id'] = test_df['id'].map(lambda x: args.base_path + '/test_images/' + str(x)+ \".jpeg\")\n",
    "FEATURE_COLS = test_df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test sd?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete abnormal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n",
       "      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n",
       "      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n",
       "      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n",
       "      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n",
       "      <th>...</th>\n",
       "      <th>X18_mean</th>\n",
       "      <th>X26_mean</th>\n",
       "      <th>X50_mean</th>\n",
       "      <th>X3112_mean</th>\n",
       "      <th>X4_sd</th>\n",
       "      <th>X11_sd</th>\n",
       "      <th>X18_sd</th>\n",
       "      <th>X26_sd</th>\n",
       "      <th>X50_sd</th>\n",
       "      <th>X3112_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_images/192027691.jpeg</td>\n",
       "      <td>12.235703</td>\n",
       "      <td>374.466675</td>\n",
       "      <td>62.524445</td>\n",
       "      <td>72.256844</td>\n",
       "      <td>773.592041</td>\n",
       "      <td>33.277779</td>\n",
       "      <td>125</td>\n",
       "      <td>149</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117484</td>\n",
       "      <td>1.243779</td>\n",
       "      <td>1.849375</td>\n",
       "      <td>50.216034</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>1.601473</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>0.153608</td>\n",
       "      <td>0.279610</td>\n",
       "      <td>15.045054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_images/195542235.jpeg</td>\n",
       "      <td>17.270556</td>\n",
       "      <td>90.239998</td>\n",
       "      <td>10.351111</td>\n",
       "      <td>38.220940</td>\n",
       "      <td>859.193298</td>\n",
       "      <td>40.009777</td>\n",
       "      <td>124</td>\n",
       "      <td>144</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389315</td>\n",
       "      <td>0.642940</td>\n",
       "      <td>1.353468</td>\n",
       "      <td>574.098472</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>11.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_images/196639184.jpeg</td>\n",
       "      <td>14.254504</td>\n",
       "      <td>902.071411</td>\n",
       "      <td>49.642857</td>\n",
       "      <td>17.873655</td>\n",
       "      <td>387.977753</td>\n",
       "      <td>22.807142</td>\n",
       "      <td>107</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>8.552908</td>\n",
       "      <td>0.395241</td>\n",
       "      <td>2.343153</td>\n",
       "      <td>1130.096731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_images/195728812.jpeg</td>\n",
       "      <td>18.680834</td>\n",
       "      <td>1473.933350</td>\n",
       "      <td>163.100006</td>\n",
       "      <td>45.009758</td>\n",
       "      <td>381.053986</td>\n",
       "      <td>20.436666</td>\n",
       "      <td>120</td>\n",
       "      <td>131</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083629</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>1.155308</td>\n",
       "      <td>1042.686546</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>2.818356</td>\n",
       "      <td>0.110673</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.229224</td>\n",
       "      <td>141.857187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_images/195251545.jpeg</td>\n",
       "      <td>0.673204</td>\n",
       "      <td>530.088867</td>\n",
       "      <td>50.857777</td>\n",
       "      <td>38.230709</td>\n",
       "      <td>1323.526855</td>\n",
       "      <td>45.891998</td>\n",
       "      <td>91</td>\n",
       "      <td>146</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657585</td>\n",
       "      <td>10.919966</td>\n",
       "      <td>2.246226</td>\n",
       "      <td>2386.467180</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>1.128000</td>\n",
       "      <td>0.026996</td>\n",
       "      <td>0.553815</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>87.146899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55484</th>\n",
       "      <td>train_images/190558785.jpeg</td>\n",
       "      <td>19.472172</td>\n",
       "      <td>244.795914</td>\n",
       "      <td>39.127552</td>\n",
       "      <td>67.074493</td>\n",
       "      <td>472.710358</td>\n",
       "      <td>27.758673</td>\n",
       "      <td>118</td>\n",
       "      <td>140</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233690</td>\n",
       "      <td>1.783193</td>\n",
       "      <td>1.608341</td>\n",
       "      <td>969.547831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55485</th>\n",
       "      <td>train_images/194523231.jpeg</td>\n",
       "      <td>13.724150</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>162.260208</td>\n",
       "      <td>43.139324</td>\n",
       "      <td>652.716858</td>\n",
       "      <td>26.694387</td>\n",
       "      <td>125</td>\n",
       "      <td>144</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017099</td>\n",
       "      <td>12.713048</td>\n",
       "      <td>2.418300</td>\n",
       "      <td>1630.015481</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.117010</td>\n",
       "      <td>3.164520</td>\n",
       "      <td>0.082212</td>\n",
       "      <td>136.503697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55486</th>\n",
       "      <td>train_images/195888987.jpeg</td>\n",
       "      <td>14.741204</td>\n",
       "      <td>581.866638</td>\n",
       "      <td>109.231110</td>\n",
       "      <td>89.272148</td>\n",
       "      <td>507.273010</td>\n",
       "      <td>26.874668</td>\n",
       "      <td>118</td>\n",
       "      <td>155</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>2.717395</td>\n",
       "      <td>10.206478</td>\n",
       "      <td>2.722599</td>\n",
       "      <td>602.229880</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.215040</td>\n",
       "      <td>0.156309</td>\n",
       "      <td>0.919139</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>26.159626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55487</th>\n",
       "      <td>train_images/135487319.jpeg</td>\n",
       "      <td>16.094763</td>\n",
       "      <td>1180.838135</td>\n",
       "      <td>80.176193</td>\n",
       "      <td>22.909716</td>\n",
       "      <td>342.184021</td>\n",
       "      <td>17.346190</td>\n",
       "      <td>109</td>\n",
       "      <td>130</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>4.429659</td>\n",
       "      <td>9.372170</td>\n",
       "      <td>3.251739</td>\n",
       "      <td>244.387170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55488</th>\n",
       "      <td>train_images/146608105.jpeg</td>\n",
       "      <td>24.559971</td>\n",
       "      <td>1748.857178</td>\n",
       "      <td>272.821442</td>\n",
       "      <td>51.363777</td>\n",
       "      <td>73.158348</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>124</td>\n",
       "      <td>135</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827227</td>\n",
       "      <td>154.773325</td>\n",
       "      <td>1.523978</td>\n",
       "      <td>3740.065673</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.231755</td>\n",
       "      <td>0.039644</td>\n",
       "      <td>10.867344</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>250.744389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55489 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  WORLDCLIM_BIO1_annual_mean_temperature  \\\n",
       "0      train_images/192027691.jpeg                               12.235703   \n",
       "1      train_images/195542235.jpeg                               17.270556   \n",
       "2      train_images/196639184.jpeg                               14.254504   \n",
       "3      train_images/195728812.jpeg                               18.680834   \n",
       "4      train_images/195251545.jpeg                                0.673204   \n",
       "...                            ...                                     ...   \n",
       "55484  train_images/190558785.jpeg                               19.472172   \n",
       "55485  train_images/194523231.jpeg                               13.724150   \n",
       "55486  train_images/195888987.jpeg                               14.741204   \n",
       "55487  train_images/135487319.jpeg                               16.094763   \n",
       "55488  train_images/146608105.jpeg                               24.559971   \n",
       "\n",
       "       WORLDCLIM_BIO12_annual_precipitation  \\\n",
       "0                                374.466675   \n",
       "1                                 90.239998   \n",
       "2                                902.071411   \n",
       "3                               1473.933350   \n",
       "4                                530.088867   \n",
       "...                                     ...   \n",
       "55484                            244.795914   \n",
       "55485                           1450.000000   \n",
       "55486                            581.866638   \n",
       "55487                           1180.838135   \n",
       "55488                           1748.857178   \n",
       "\n",
       "       WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n",
       "0                                              62.524445                       \n",
       "1                                              10.351111                       \n",
       "2                                              49.642857                       \n",
       "3                                             163.100006                       \n",
       "4                                              50.857777                       \n",
       "...                                                  ...                       \n",
       "55484                                          39.127552                       \n",
       "55485                                         162.260208                       \n",
       "55486                                         109.231110                       \n",
       "55487                                          80.176193                       \n",
       "55488                                         272.821442                       \n",
       "\n",
       "       WORLDCLIM_BIO15_precipitation_seasonality  \\\n",
       "0                                      72.256844   \n",
       "1                                      38.220940   \n",
       "2                                      17.873655   \n",
       "3                                      45.009758   \n",
       "4                                      38.230709   \n",
       "...                                          ...   \n",
       "55484                                  67.074493   \n",
       "55485                                  43.139324   \n",
       "55486                                  89.272148   \n",
       "55487                                  22.909716   \n",
       "55488                                  51.363777   \n",
       "\n",
       "       WORLDCLIM_BIO4_temperature_seasonality  \\\n",
       "0                                  773.592041   \n",
       "1                                  859.193298   \n",
       "2                                  387.977753   \n",
       "3                                  381.053986   \n",
       "4                                 1323.526855   \n",
       "...                                       ...   \n",
       "55484                              472.710358   \n",
       "55485                              652.716858   \n",
       "55486                              507.273010   \n",
       "55487                              342.184021   \n",
       "55488                               73.158348   \n",
       "\n",
       "       WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n",
       "0                                    33.277779                            125   \n",
       "1                                    40.009777                            124   \n",
       "2                                    22.807142                            107   \n",
       "3                                    20.436666                            120   \n",
       "4                                    45.891998                             91   \n",
       "...                                        ...                            ...   \n",
       "55484                                27.758673                            118   \n",
       "55485                                26.694387                            125   \n",
       "55486                                26.874668                            118   \n",
       "55487                                17.346190                            109   \n",
       "55488                                13.400000                            124   \n",
       "\n",
       "       SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  \\\n",
       "0                                    149                              136   \n",
       "1                                    144                              138   \n",
       "2                                    133                              119   \n",
       "3                                    131                              125   \n",
       "4                                    146                              120   \n",
       "...                                  ...                              ...   \n",
       "55484                                140                              131   \n",
       "55485                                144                              135   \n",
       "55486                                155                              136   \n",
       "55487                                130                              117   \n",
       "55488                                135                              131   \n",
       "\n",
       "       ...  X18_mean    X26_mean  X50_mean   X3112_mean     X4_sd    X11_sd  \\\n",
       "0      ...  0.117484    1.243779  1.849375    50.216034  0.008921  1.601473   \n",
       "1      ...  0.389315    0.642940  1.353468   574.098472  0.003102  0.258078   \n",
       "2      ...  8.552908    0.395241  2.343153  1130.096731       NaN       NaN   \n",
       "3      ...  1.083629    0.154200  1.155308  1042.686546  0.011692  2.818356   \n",
       "4      ...  0.657585   10.919966  2.246226  2386.467180  0.006157  1.128000   \n",
       "...    ...       ...         ...       ...          ...       ...       ...   \n",
       "55484  ...  0.233690    1.783193  1.608341   969.547831       NaN       NaN   \n",
       "55485  ...  1.017099   12.713048  2.418300  1630.015481  0.005474  0.128133   \n",
       "55486  ...  2.717395   10.206478  2.722599   602.229880  0.019727  0.215040   \n",
       "55487  ...  4.429659    9.372170  3.251739   244.387170       NaN       NaN   \n",
       "55488  ...  5.827227  154.773325  1.523978  3740.065673  0.004373  0.231755   \n",
       "\n",
       "         X18_sd     X26_sd    X50_sd    X3112_sd  \n",
       "0      0.025441   0.153608  0.279610   15.045054  \n",
       "1      0.000866   0.034630  0.010165   11.004477  \n",
       "2           NaN        NaN       NaN         NaN  \n",
       "3      0.110673   0.011334  0.229224  141.857187  \n",
       "4      0.026996   0.553815  0.107092   87.146899  \n",
       "...         ...        ...       ...         ...  \n",
       "55484       NaN        NaN       NaN         NaN  \n",
       "55485  0.117010   3.164520  0.082212  136.503697  \n",
       "55486  0.156309   0.919139  0.079395   26.159626  \n",
       "55487       NaN        NaN       NaN         NaN  \n",
       "55488  0.039644  10.867344  0.009248  250.744389  \n",
       "\n",
       "[55489 rows x 176 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "quntilelist=np.array(train_df[args.label_features].quantile([0,0.95]))\n",
    "IQR=quntilelist[1]-quntilelist[0]\n",
    "low_bound=quntilelist[0]-1.5*IQR\n",
    "upper_bound=quntilelist[1]+1.5*IQR\n",
    "for i in range(len(args.label_features)):\n",
    "    train_df = train_df[(train_df[args.label_features[i]] < upper_bound[i]) & (train_df[args.label_features[i]] > low_bound[i]) | train_df[args.label_features[i]].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "quntilelist=np.array(train_df[args.sd_features].quantile([0,0.95]))\n",
    "IQR=quntilelist[1]-quntilelist[0]\n",
    "low_bound=quntilelist[0]-1.5*IQR\n",
    "upper_bound=quntilelist[1]+1.5*IQR\n",
    "for i in range(len(args.sd_features)):\n",
    "    train_df = train_df[(train_df[args.sd_features[i]] < upper_bound[i]) & (train_df[args.sd_features[i]] > low_bound[i]) | train_df[args.sd_features[i]].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = train_df[args.label_features+args.sd_features]\n",
    "train_df = train_df.drop(columns = args.label_features+args.sd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = train_test_split(train_df, label_df, test_size=0.1)\n",
    "x_train_images = np.array(x_train['id']) \n",
    "x_train = x_train.drop(columns = 'id')\n",
    "x_val_images = np.array(x_val['id']) \n",
    "x_val = x_val.drop(columns = 'id')\n",
    "y_train,y_val = np.array(y_train).astype(np.float32), np.array(y_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "train_features = scaler.fit_transform(x_train[FEATURE_COLS].values).astype(np.float32)\n",
    "valid_features = scaler.transform(x_val[FEATURE_COLS].values).astype(np.float32)\n",
    "\n",
    "train_labels = y_train[:,:6]\n",
    "train_labels_aux = y_train[:,6:]\n",
    "val_labels = y_val[:,:6]\n",
    "val_labels_aux = y_val[:,6:]\n",
    "\n",
    "train_features[np.isnan(train_features)] = -1\n",
    "valid_features[np.isnan(valid_features)] = -1\n",
    "train_labels[np.isnan(train_labels)] = -1\n",
    "train_labels_aux[np.isnan(train_labels_aux)] = -1\n",
    "val_labels[np.isnan(val_labels)] = -1\n",
    "val_labels_aux[np.isnan(val_labels_aux)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [(x_train_images[i], train_features[i],train_labels[i], train_labels_aux[i] ) for i in range(len(x_train_images))]\n",
    "val_dataset = [(x_val_images[i], valid_features[i],val_labels[i],val_labels_aux[i]) for i in range(len(x_val_images))]\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size=args.BATCH_SIZE , shuffle= True, num_workers = 2)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size=args.BATCH_SIZE , shuffle= False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopad(k, p=None):  # kernel, padding\n",
    "    # Pad to 'same'\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    # Standard convolution\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1,\n",
    "                 act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(c2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoV2(nn.Module):\n",
    "    def __init__(self,args) ->None:\n",
    "        super(DinoV2,self).__init__()\n",
    "        self.backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "        # autocast_ctx = partial(torch.cuda.amp.autocast, enabled=True, dtype=torch.float16)\n",
    "        if args.pretrain_choice == 'frozen':\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        # self.feature_model = ModelWithIntermediateLayers(self.backbone, n_last_blocks=1, autocast_ctx=autocast_ctx)\n",
    "        # self.classifier = LinearClassifier(self.in_planes*2, use_n_blocks=1, use_avgpool=True, num_classes=10)\n",
    "        self.in_planes = self.backbone.embed_dim\n",
    "        self.consize = int((args.img_size/args.patch_size)*(args.img_size/args.patch_size))\n",
    "        if args.decoder == 'Conv':\n",
    "            self.decoder = ConvDecoder(self.consize,self.in_planes)\n",
    "        elif args.decoder == 'Linear':\n",
    "            self.decoder = LinearDecoder(self.consize,self.in_planes)\n",
    "       \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.backbone.get_intermediate_layers(x, n=1, reshape=False, norm=True, return_class_token=True)[0]\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "class LinearDecoder(nn.Module):\n",
    "    def __init__(self,in_dim,emb_dim) ->None:\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(in_dim,1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc = nn.Linear(emb_dim*2,128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.head.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.head.bias.data.zero_()\n",
    "        self.fc.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self,x):\n",
    "        feature, class_token = x\n",
    "        feature = rearrange(feature,'b h c -> b c h') #[batch_size,(img_size/14)**2,384] --> [batch_size,384,1]\n",
    "        feature = self.head(feature)\n",
    "        feature = self.relu1(feature)\n",
    "        feature = torch.squeeze(feature) #[batch_size,384]\n",
    "        x0 = torch.cat([feature, class_token],dim=1)\n",
    "        x0 = self.fc(x0)\n",
    "        x0 = self.relu2(x0)\n",
    "        return x0\n",
    "    \n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self,c0,c1,dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv(c0, c0)\n",
    "        self.conv2 = Conv(c0, c0)\n",
    "        self.drop = nn.Dropout(p= dropout)\n",
    "\n",
    "        self.linear = nn.Linear(c1 * 2, 128)\n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature, class_token = x\n",
    "        feature, class_token = torch.cat([feature.detach()], dim=-1), torch.cat([class_token.detach()], dim=-1)\n",
    "        feature = self.drop(self.conv2(self.conv1(feature)))\n",
    "        x0 = torch.cat((torch.mean(feature, dim=1), class_token), dim=-1) #concate features and cls_token\n",
    "        return self.linear(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(163, 326), nn.SELU(), nn.Linear(326, 256), nn.SELU())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(256, 128), nn.SELU(), nn.Linear(128, 64), nn.SELU())\n",
    "        self.dropout = nn.Dropout()\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x  \n",
    "    \n",
    "class Combine_model(nn.Module):\n",
    "    def __init__(self,args) -> None:\n",
    "        super(Combine_model,self).__init__()\n",
    "        # self.model1 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model1 = DinoV2(args) #output size [batch,(H/patch_size)*(W/patch_size),768]\n",
    "        self.model2 = MLP()\n",
    "        self.out_fc1 = nn.Sequential(\n",
    "            nn.Linear(128+64,24), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24,6)\n",
    "        )\n",
    "        self.out_fc2 = nn.Sequential(\n",
    "            nn.Linear(128+64,24), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24,6)\n",
    "        )\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        x = self.model1(x)\n",
    "        y = self.model2(y)\n",
    "        x = torch.cat([x,y], dim = 1)\n",
    "        return self.out_fc1(x), self.out_fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(imgs,img_size,type='train',backbone='ResNet'):\n",
    "        \n",
    "    if type == 'train':\n",
    "         trans = transforms.Compose([\n",
    "                    transforms.Resize((img_size, img_size)),\n",
    "                    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=(0.45, 0.55), hue=0.1),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.RandomRotation((-10,10)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "                ])\n",
    "    elif type == 'validate':\n",
    "        trans = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "            ])\n",
    "        \n",
    "    return trans(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self, use_mask=False):\n",
    "        super(R2Loss, self).__init__()\n",
    "        self.use_mask = use_mask\n",
    "\n",
    "    def forward(self,y_pred , y_true):\n",
    "        if self.use_mask:\n",
    "            mask = (y_true != -1)\n",
    "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
    "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2,axis=0)\n",
    "        SS_tot = torch.sum((y_true - torch.mean(y_true, 1, True)) ** 2,axis=0)\n",
    "        r2_loss = SS_res / (SS_tot + 1e-6)\n",
    "        return torch.mean(r2_loss)\n",
    "    \n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self, use_mask=False):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.use_mask = use_mask\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        if self.use_mask:\n",
    "            mask = (y_true != -1)\n",
    "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
    "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
    "        mse_loss = torch.mean((y_true - y_pred) ** 2)\n",
    "        return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader,model, criterion1, criterion2, optimizer, scheduler, device,args):\n",
    "    args.run_type = 'train'\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        # Unpack data\n",
    "        img_path, inputs, labels, labels_aux = data\n",
    "        \n",
    "        # Prepare image paths\n",
    "        # # Prepare inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels_aux = labels_aux.to(device)\n",
    "\n",
    "        # Load and transform images\n",
    "        batch_size = len(img_path)\n",
    "        images = torch.zeros(batch_size, 3, args.img_size, args.img_size, dtype=torch.float32)\n",
    "        for i in range(batch_size):\n",
    "            image = Image.open(img_path[i]).convert(\"RGB\")\n",
    "            images[i] = transform(image,args.img_size,args.run_type,args.backbone)  # Assuming train_transform is defined elsewhere\n",
    "        # Forward pass\n",
    "        images = images.to(device)\n",
    "        output1,output2 = model(images, inputs)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss1 = criterion1[0](output1, labels)       \n",
    "        loss2 = criterion2[0](output2,labels_aux) \n",
    "        loss = loss1 + 0.2*loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(test_loader,model,criterion1,criterion2,device,args):\n",
    "    model.eval()\n",
    "    args.run_type = 'validate'\n",
    "    total_loss = 0\n",
    "    total_r2_loss = 0\n",
    "    output = []\n",
    "    total_label = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(test_loader)):\n",
    "            # Unpack data\n",
    "            img_path, inputs, labels, labels_aux = data\n",
    "            # Prepare image paths\n",
    "            # # Prepare inputs and labels\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels_aux = labels_aux.to(device)\n",
    "\n",
    "            batch_size = len(img_path)\n",
    "            images = torch.zeros(batch_size, 3, args.img_size, args.img_size, dtype=torch.float32)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                image = Image.open(img_path[i]).convert(\"RGB\")\n",
    "                images[i] = transform(image,args.img_size,args.run_type,args.backbone)   # Assuming train_transform is defined elsewhere\n",
    "            # Forward pass\n",
    "            images = images.to(device)\n",
    "            output1,output2 = model(images, inputs)\n",
    "            output.append(output1)\n",
    "            total_label.append(labels)\n",
    "            loss1 = criterion1[0](output1, labels) + 0.2*criterion2[0](output2,labels_aux)     \n",
    "            loss2 = criterion1[0](output1, labels)\n",
    "            total_r2_loss += loss2.item()\n",
    "            total_loss += loss1.item()\n",
    "            total_r2 = criterion1[0](torch.cat(output, dim = 0), torch.cat(total_label, dim = 0))\n",
    "        avg_loss = total_loss/len(test_loader)\n",
    "        avg_r2_loss = total_r2_loss/len(test_loader)\n",
    "    return avg_loss, avg_r2_loss, total_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\A/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [05:45,  2.03s/it]"
     ]
    }
   ],
   "source": [
    "args.backbone = 'DinoV2'\n",
    "args.BATCH_SIZE = 128\n",
    "args.patch_size = 14\n",
    "args.pretrain_choice = 'frozen'\n",
    "args.decoder = 'Linear'\n",
    "loses = []\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Combine_model(args).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=args.weight_decay, lr=args.LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.MAX_EPOCH, eta_min=0, last_epoch=-1)\n",
    "criterion1 = [R2Loss(use_mask=False), MSELoss(use_mask=False)]\n",
    "criterion2 = [R2Loss(use_mask=True), MSELoss(use_mask=True)]\n",
    "best_r2 = -5\n",
    "args.output_path = '/kaggle/working/'\n",
    "# set log\n",
    "logging.basicConfig(filename=f'{args.output_path}/train_{args.backbone}_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "for epoch in range(args.MAX_EPOCH):\n",
    "    print('epoch',epoch)\n",
    "    train_loss = train_epoch(train_loader,model,criterion1,criterion2,optimizer,scheduler,device,args)\n",
    "    test_loss, test_r2_loss, total_R2 = evaluate_epoch(val_loader,model, criterion1,criterion2, device, args)\n",
    "    best_r2 = max(best_r2, 1 - total_R2)\n",
    "    print(\"Train_loss is: {}, test loss is: {}, test R2 loss is: {}, test R2 is: {}, current best result: {}\".format(train_loss, test_loss, test_r2_loss, 1 - total_R2, best_r2))\n",
    "    logging.info(\"Epoch %s\", epoch)\n",
    "    logging.info(\"Train loss: %s\", train_loss)\n",
    "    logging.info(\"Test loss: %s\", test_loss)\n",
    "    logging.info(\"Test R2 loss: %s\", test_r2_loss)\n",
    "    logging.info(\"Test R2: %s\", 1 - total_R2)\n",
    "    loses.append([train_loss, test_r2_loss, test_r2_loss, total_R2])\n",
    "    if best_r2 == 1 - total_R2:\n",
    "        torch.save(model, args.output_path + \"/Dino.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [train_losses, test_losses]\n",
    "point = pd.DataFrame(losses,columns=np.arange(1,MAX_EPOCH+1),index=['train','test']).T\n",
    "ax=sns.lineplot(data=point)\n",
    "ax.set(xlabel='epoch',ylabel='R2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
