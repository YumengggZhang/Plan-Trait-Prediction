{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix ,roc_curve,roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'planttraits2024/train.csv'\n",
    "test_path = 'planttraits2024/test.csv'\n",
    "MAX_EPOCH = 5\n",
    "BATCH_SIZE = 1\n",
    "weight_decay = 1e-3\n",
    "LR=0.0001\n",
    "img_size = 128\n",
    "sd_features = ['X4_sd', 'X11_sd','X18_sd', 'X26_sd', 'X50_sd', 'X3112_sd']\n",
    "label_features = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'planttraits2024/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhangyumeng/Desktop/23Winter/273P/project/main 2.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(train_path)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(test_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39mtrain_images/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39mtest_images/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'planttraits2024/test.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df['id'] = train_df['id'].map(lambda x: 'train_images/' + str(x)+ \".jpeg\")\n",
    "test_df['id'] = test_df['id'].map(lambda x: 'test_images/' + str(x)+ \".jpeg\")\n",
    "FEATURE_COLS = test_df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test sd?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete abnormal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "quntilelist=np.array(train_df[label_features].quantile([0,0.99]))\n",
    "IQR=quntilelist[1]-quntilelist[0]\n",
    "low_bound=quntilelist[0]-1.5*IQR\n",
    "upper_bound=quntilelist[1]+1.5*IQR\n",
    "\n",
    "for i in range(len(label_features)):\n",
    "    train_df[label_features[i]] = np.where((train_df[label_features[i]]<upper_bound[i])&(train_df[label_features[i]]>low_bound[i]),\\\n",
    "                                           train_df[label_features[i]],-1)\n",
    "for i in range(len(label_features)):\n",
    "    train_df = train_df[train_df[label_features[i]]!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = train_df[label_features+sd_features]\n",
    "x_train,x_val,y_train,y_val = train_test_split(train_df, label_df, test_size=0.3)\n",
    "x_train_images = np.array(x_train['id']) \n",
    "x_train = x_train.drop(columns = 'id')\n",
    "x_val_images = np.array(x_val['id']) \n",
    "x_val = x_val.drop(columns = 'id')\n",
    "y_train,y_val = np.array(y_train).astype(np.float32), np.array(y_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19305.188"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[np.isnan(y_train)] = -1\n",
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "train_features = scaler.fit_transform(x_train[FEATURE_COLS].values).astype(np.float32)\n",
    "valid_features = scaler.transform(x_val[FEATURE_COLS].values).astype(np.float32)\n",
    "\n",
    "scaler_y = RobustScaler()\n",
    "train_labels = y_train\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "\n",
    "train_labels = y_train[:,:6]\n",
    "train_labels_aux = y_train[:,6:]\n",
    "val_labels = y_val[:,:6]\n",
    "val_labels_aux = y_val[:,6:]\n",
    "\n",
    "train_features[np.isnan(train_features)] = -1\n",
    "valid_features[np.isnan(valid_features)] = -1\n",
    "train_labels[np.isnan(train_labels)] = -1\n",
    "train_labels_aux[np.isnan(train_labels_aux)] = -1\n",
    "val_labels[np.isnan(val_labels)] = -1\n",
    "val_labels_aux[np.isnan(val_labels_aux)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.721268"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [(x_train_images[i], train_features[i],train_labels[i], train_labels_aux[i] ) for i in range(len(x_train_images))]\n",
    "val_dataset = [(x_val_images[i], valid_features[i],val_labels[i],val_labels_aux[i]) for i in range(len(x_val_images))]\n",
    "train_loader = DataLoader(dataset = train_dataset[:200], batch_size=BATCH_SIZE , shuffle= True, num_workers = 0)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size=BATCH_SIZE , shuffle= False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(163, 326), nn.SELU(),nn.Dropout())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(326, 64), nn.SELU(),nn.Dropout())\n",
    "        self.dropout = nn.Dropout()\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Combine_model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Combine_model,self).__init__()\n",
    "        self.model1 = models.resnet18(pretrained=False)\n",
    "        self.model1.fc=nn.Sequential(\n",
    "            nn.Linear(self.model1.fc.in_features, 128), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.model2 = MLP()\n",
    "        self.fc = nn.Linear(128+64, 6)\n",
    "        self.out_fc1 = nn.Linear(128+64,6)\n",
    "        self.out_fc2 = nn.Sequential(\n",
    "            nn.Linear(128+64,6), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        x = self.model1(x)\n",
    "        y = self.model2(y)\n",
    "        x = torch.cat([x,y], dim = 1)\n",
    "        out1 = self.out_fc1(x)\n",
    "        out2 = self.out_fc2(x)\n",
    "        \n",
    "        return out1, out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomResizedCrop(size=img_size, scale=(0.8, 1.0), ratio=(0.8, 1.25)),\n",
    "        transforms.RandomRotation((-45,45)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.18,0.18,0.18], std=[0.24,0.24,0.24])\n",
    "    ])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.18,0.18,0.18], std=[0.24,0.24,0.24])\n",
    "])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "model = Combine_model()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self, use_mask=False):\n",
    "        super(R2Loss, self).__init__()\n",
    "        self.use_mask = use_mask\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        if self.use_mask:\n",
    "            mask = (y_true != -1)\n",
    "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
    "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2,axis=0)\n",
    "        SS_tot = torch.sum((y_true - torch.mean(y_true)) ** 2,axis=0)\n",
    "        r2_loss = SS_res / (SS_tot + 1e-6)\n",
    "        return torch.mean(r2_loss)\n",
    "    \n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self, use_mask=False):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.use_mask = use_mask\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        if self.use_mask:\n",
    "            mask = (y_true != -1)\n",
    "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
    "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
    "\n",
    "        mse_loss = torch.mean((y_true - y_pred) ** 2)\n",
    "        return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader,model, criterion1, criterion2, optimizer, scheduler, device, img_size):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        # Unpack data\n",
    "        img_path, inputs, labels, labels_aux = data\n",
    "\n",
    "        # Prepare image paths\n",
    "        img_path = ['/Users/zhangyumeng/Desktop/23Winter/273P/project/planttraits2024/'+i for i in img_path]\n",
    "\n",
    "        # # Prepare inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Load and transform images\n",
    "        batch_size = len(img_path)\n",
    "        images = torch.zeros(batch_size, 3, img_size, img_size, dtype=torch.float32)\n",
    "        for i in range(batch_size):\n",
    "            # image = cv2.imread(img_path[i]).numpy()\n",
    "            image = Image.open(img_path[i]).convert(\"RGB\")\n",
    "            # images[i] = image\n",
    "            images[i] = train_transform(image)  # Assuming train_transform is defined elsewhere\n",
    "        # Forward pass\n",
    "        # images = images.to(device)\n",
    "        output1,output2 = model(images, inputs)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss1 = criterion1(labels, output1)\n",
    "        loss2 = criterion2(labels_aux, output2)\n",
    "         \n",
    "        loss = loss1+loss2\n",
    "\n",
    "        if loss1 <= 1000:\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss1.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(test_loader,model,criterion1,criterion2,device,img_size):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for i, data in tqdm(enumerate(test_loader)):\n",
    "        # Unpack data\n",
    "        img_path, inputs, labels, labels_aux = data\n",
    "\n",
    "        # Prepare image paths\n",
    "        img_path = ['/Users/zhangyumeng/Desktop/23Winter/273P/project/planttraits2024/'+i for i in img_path]\n",
    "\n",
    "        # # Prepare inputs and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        batch_size = len(img_path)\n",
    "        images = torch.zeros(batch_size, 3, img_size, img_size, dtype=torch.float32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # image = cv2.imread(img_path[i]).numpy()\n",
    "            image = Image.open(img_path[i]).convert(\"RGB\")\n",
    "            images[i] = train_transform(image)  # Assuming train_transform is defined elsewhere\n",
    "        # Forward pass\n",
    "        # images = images.to(device)\n",
    "        output1,output2 = model(images, inputs)\n",
    "        loss1 = criterion1(output1, labels)       \n",
    "        loss2 = criterion2(output2,labels_aux)\n",
    "        print('loss1',loss1)\n",
    "        print('loss2',loss2)\n",
    "        loss = loss1+loss2\n",
    "        total_loss += loss\n",
    "    avg_loss = total_loss/len(test_loader)\n",
    "    return avg_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyumeng/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/zhangyumeng/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:21,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.4789\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:20,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.3464\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:21,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.2042\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:20,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.1531\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:20,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model.to(device)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Combine_model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                T_max=MAX_EPOCH,\n",
    "                                                eta_min=0,\n",
    "                                                last_epoch=-1)\n",
    "criterion1 = MSELoss(use_mask=False)\n",
    "criterion2 = MSELoss(use_mask=True)\n",
    "\n",
    "for _ in range(MAX_EPOCH):\n",
    "    print('epoch',_)\n",
    "    train_epoch(train_loader,model,criterion1,criterion2,optimizer,scheduler,device,img_size)\n",
    "    # evaluate_epoch(val_loader,model, criterion1,criterion2, device, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyumeng/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/zhangyumeng/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "7it [00:00, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(1265.7909, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1854.7197, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(13.4011, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(191.0170, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(4414.2993, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(27.7515, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(7.2002, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(29.5333, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(678.4037, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1646.3619, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(2650.4602, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(190.2494, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(114.4610, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(42.9691, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 29.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(37233.1992, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(46785.9883, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(22.9265, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(69.5529, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(460.8175, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1409.1577, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(909.8994, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(6805.1777, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(9224.2285, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(17.6979, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 28.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(2016.9574, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3675.4666, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(10927.7354, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(583.0513, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(17.0351, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(170.5521, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(220.1718, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(154019.5625, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(17953.9707, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(79416.3906, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(89.2628, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4068.8037, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(810.6983, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(95.6780, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 30.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(17.5664, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(73.0215, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(359.1297, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(58.9573, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(214.6637, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2.3344, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(36.5904, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(13.6586, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(91.1746, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(5869.2485, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(51.2859, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(10706.9160, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(222.1432, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(331597.9062, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:01, 31.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(6417.8403, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(40.8572, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(161.6449, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(69.7132, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(5.7849, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(22.2734, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(45.1752, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(367.0439, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(29.7551, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(19.4671, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(93.6987, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(36.1563, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(39221.6875, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(241.3234, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:01, 31.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(63.5509, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1450.9955, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(133.4463, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3425.3113, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(21629.1895, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(82351.4453, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(229.2680, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2592.7693, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(71675.0234, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(280350.4062, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1803.5312, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(52.6698, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(34.1022, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(555.7817, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:01, 32.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(18.4125, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(63.5239, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(137.7453, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(178.7264, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(99.1489, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(274.8615, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1757.9984, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(103.8881, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(329.7784, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2288.2415, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(92.7768, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(5264.2109, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(26252.8262, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1201.9010, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:01, 32.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(847.0737, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(123.1975, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(440.0038, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3245.6628, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(111.9907, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(733.2363, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(300.1320, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(428.4137, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(56669.6055, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(182.1090, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1415.4834, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(467.8018, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(30.1760, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(338.2861, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:01, 32.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(10708.1289, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4805.6421, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(96.1527, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(26304.1230, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(6.0638, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(24.2667, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(155.9273, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(310348.4062, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(43.4371, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(40104.8281, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(38.7198, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(253.1855, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(10.7001, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(226.6382, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:02, 29.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(3004.7966, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(9267.4277, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(27.5197, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(466.7914, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(9644.4326, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(231.6871, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(41.8229, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(160.7885, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(295.4432, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(62909.1602, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(16.5364, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(15.8088, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [00:02, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(13503.5352, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(597.8780, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(76.1585, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(16.9726, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(4.6573, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(15.0736, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(79.3438, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(10.7475, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(43.9773, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2073.9197, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(11.3158, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(491.9583, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(339.1930, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3666.2664, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:02, 31.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(28.2074, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(171.8068, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(14.7603, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(7.3542, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1804.6332, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(913.3486, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1667.8956, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(17133.1465, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(15.0142, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(250.8242, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(10.8083, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(531.7445, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(2.6128, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(19.9703, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [00:02, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(855.0977, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(15123.5674, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(616.6744, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(408.6270, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(329.0895, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3157.0022, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(5.7921, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(155.6252, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(4418.1768, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(17.9410, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(4.5553, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(487.7477, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(14.9255, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(337.4615, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 32.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(26.9044, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(177.0444, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(30.5189, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(18.4933, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(84.7366, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(45.8255, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(245.9886, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(16.7881, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(10.8762, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(752.2994, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(13.6483, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(11.4471, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(63.6008, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(654.5914, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:03, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(1500.2833, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(28839.2344, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(57.6959, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(223.7110, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(3.2220, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(19.3482, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(391.0570, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(59.2469, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(499.8245, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4952.9863, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(39.4172, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(19.9892, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(82.0916, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4791.0854, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [00:03, 32.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(16260.9346, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(32.8547, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(382.9936, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(202.8863, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(280.6269, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(512.5272, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(149539.7188, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2598.6545, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(73.1257, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(89303.8750, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(3.1827, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(328.6513, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(800.2083, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(75634.6562, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114it [00:03, 33.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(8.9021, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(3.1539, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(382.3827, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(40221.1055, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(103.6110, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(10.0345, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(48.0600, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(281.6966, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(81.3305, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(62.7363, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(9.7846, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(11.9381, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(10152.8838, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(97.4408, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:03, 33.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(3217.1106, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(7473.2363, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(37.9256, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(30013.5137, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(91.3593, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4238.1011, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(125.3094, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(15.3935, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(104325.9297, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(266.4025, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(78.8427, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(21.7089, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(8605.6680, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(2017.6338, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126it [00:04, 30.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(45.1083, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(12.2760, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1842.2474, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(26984.6504, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(6.6021, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(867.7543, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(39.1557, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(138.1773, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(440.3049, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(19.1382, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(2311.6033, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(133.8015, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [00:04, 31.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(36.1301, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(14156.9854, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(53.9834, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(4808.2173, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(550.3896, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1188.6469, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(4229.7476, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(23350.2891, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(139.2299, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(922.1342, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(258.2277, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(13397.0498, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(11235.6318, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(654.1624, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138it [00:04, 27.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(852.9355, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(130.1331, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(30.7282, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(563.2174, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(11275.3350, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(185206.8125, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(288.9236, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(56.9872, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "145it [00:04, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(8.0429, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(73.7715, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(19994.8730, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(251102.4375, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(7483568.5000, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(26291.8906, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(79.3614, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(20.4362, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(247.7457, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(5437.9995, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(29.1648, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(20.8514, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(106.6345, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(150.2071, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [00:04, 30.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(273.7056, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(40.5606, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(89.8220, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(6.2711, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(383.9755, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(695.2009, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(144.2856, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1328.4877, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(47.2234, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(57.7886, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(169.0717, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(1699.9108, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(737.5786, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(56.1127, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:05, 30.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 tensor(38.8151, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(464.4643, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(70.6085, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(81.6964, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1437.2954, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(11318.5146, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(24.6140, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(197.2419, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(170.4754, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(103.1587, grad_fn=<MeanBackward0>)\n",
      "loss1 tensor(1700.4144, grad_fn=<MeanBackward0>)\n",
      "loss2 tensor(35.1899, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhangyumeng/Desktop/23Winter/273P/project/main 2.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                                 T_max\u001b[39m=\u001b[39mMAX_EPOCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                                 eta_min\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                                 last_epoch\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_EPOCH):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     evaluate_epoch(val_loader,model, criterion1,criterion2, device, img_size)\n",
      "\u001b[1;32m/Users/zhangyumeng/Desktop/23Winter/273P/project/main 2.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     images[i] \u001b[39m=\u001b[39m train_transform(image)  \u001b[39m# Assuming train_transform is defined elsewhere\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# images = images.to(device)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m output1,output2 \u001b[39m=\u001b[39m model(images, inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss1 \u001b[39m=\u001b[39m criterion1(output1, labels)       \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss2 \u001b[39m=\u001b[39m criterion2(output2,labels_aux)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/zhangyumeng/Desktop/23Winter/273P/project/main 2.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x,y):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel2(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangyumeng/Desktop/23Winter/273P/project/main%202.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x,y], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[1;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Combine_model()\n",
    "criterion1 = R2Loss(use_mask=False)\n",
    "criterion2 = R2Loss(use_mask=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                T_max=MAX_EPOCH,\n",
    "                                                eta_min=0,\n",
    "                                                last_epoch=-1)\n",
    "for _ in range(MAX_EPOCH):\n",
    "    evaluate_epoch(val_loader,model, criterion1,criterion2, device, img_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
