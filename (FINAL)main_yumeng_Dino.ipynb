{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# # get access to mydrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "d3CL6M_3QlWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WnJyYxpQinY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix ,roc_curve,roc_auc_score\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from einops import rearrange\n",
        "\n",
        "import logging\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa71a2LQinc"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "XkPzJZQVZEe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byrLV3y8Qind"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    base_path = \"/content/drive/MyDrive/273P-final/data\"\n",
        "    output_path = base_path + '/output'\n",
        "    train_path = base_path + '/train.csv'\n",
        "    test_path = base_path + '/test.csv'\n",
        "    backbone = 'Resnet18'\n",
        "\n",
        "    sd_features = ['X4_sd', 'X11_sd','X18_sd', 'X26_sd', 'X50_sd', 'X3112_sd']\n",
        "    label_features = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
        "\n",
        "    MAX_EPOCH = 200\n",
        "    BATCH_SIZE = 128\n",
        "    weight_decay = 1e-3\n",
        "    LR=0.0001\n",
        "    img_size = 140\n",
        "\n",
        "    DEBUG = True\n",
        "    data_slice = BATCH_SIZE if DEBUG else -1\n",
        "\n",
        "args = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyGcDKRoQing"
      },
      "source": [
        "### Delete abnormal values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Qn7JC3Qini"
      },
      "outputs": [],
      "source": [
        "# outliers\n",
        "def delete_abnormal_values(df, feature:list()):\n",
        "    quntilelist=np.array(df[feature].quantile([0,0.95]))\n",
        "    IQR=quntilelist[1]-quntilelist[0]\n",
        "    low_bound=quntilelist[0]-1.5*IQR\n",
        "    upper_bound=quntilelist[1]+1.5*IQR\n",
        "    for i in range(len(feature)):\n",
        "        df = df[(df[feature[i]] < upper_bound[i]) & (df[feature[i]] > low_bound[i]) | df[feature[i]].isna()]\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "9R_4ggn2bBOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BdZwflRQinm"
      },
      "outputs": [],
      "source": [
        "def autopad(k, p=None):  # kernel, padding\n",
        "    # Pad to 'same'\n",
        "    if p is None:\n",
        "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
        "    return p\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    # Standard convolution\n",
        "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1,\n",
        "                 act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(c2)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOS8GqQOQinn"
      },
      "outputs": [],
      "source": [
        "class Resnet18(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Resnet18, self).__ini__()\n",
        "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(self.backbone.head.fc.in_features, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout()\n",
        "        )\n",
        "\n",
        "    def forward(self):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DinoV2(nn.Module):\n",
        "    def __init__(self,args) ->None:\n",
        "        super(DinoV2,self).__init__()\n",
        "        self.backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "        if args.pretrain_choice == 'frozen':\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.in_planes = self.backbone.embed_dim\n",
        "\n",
        "        self.consize = int((args.img_size/args.patch_size)*(args.img_size/args.patch_size))\n",
        "\n",
        "        if args.decoder == 'Conv':\n",
        "            self.decoder = ConvDecoder(self.consize,self.in_planes)\n",
        "        elif args.decoder == 'Linear':\n",
        "            self.decoder = LinearDecoder(self.consize,self.in_planes)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        #x (batch, 3, 128, 128)\n",
        "        x = self.backbone.get_intermediate_layers(x, n=1, reshape=False, norm=True, return_class_token=True)[0]\n",
        "        # feature(batch, (imgsize/patch_size) ** 2, 384) ; cls_token(3, 384)\n",
        "\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class LinearDecoder(nn.Module):\n",
        "    def __init__(self,in_dim,emb_dim) ->None:\n",
        "        super().__init__()\n",
        "        self.head = nn.Linear(in_dim,1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc = nn.Linear(emb_dim*2,128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.head.weight.data.normal_(mean=0.0, std=0.01)\n",
        "        self.head.bias.data.zero_()\n",
        "        self.fc.weight.data.normal_(mean=0.0, std=0.01)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self,x):\n",
        "        feature, class_token = x\n",
        "        feature = rearrange(feature,'b h c -> b c h') #[batch_size,(img_size/14)**2,384] --> [batch_size,384,1]\n",
        "        feature = self.head(feature)\n",
        "        feature = self.relu1(feature)\n",
        "        feature = torch.squeeze(feature) #\n",
        "\n",
        "        x0 = torch.cat([feature, class_token],dim=1) # [batch_size, 768]\n",
        "        x0 = self.fc(x0)\n",
        "        x0 = self.relu2(x0)\n",
        "        return x0\n",
        "\n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self,c0,c1,dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(c0, c0)\n",
        "        self.conv2 = Conv(c0, c0)\n",
        "        self.drop = nn.Dropout(p= dropout)\n",
        "\n",
        "        self.linear = nn.Linear(c1 * 2, 128)\n",
        "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature, class_token = x\n",
        "        feature, class_token = torch.cat([feature.detach()], dim=-1), torch.cat([class_token.detach()], dim=-1)\n",
        "        feature = self.drop(self.conv2(self.conv1(feature)))\n",
        "        x0 = torch.cat((torch.mean(feature, dim=1), class_token), dim=-1) #concate features and cls_token\n",
        "        return self.relu(self.linear(x0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhf6y-IpQino"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(MLP,self).__init__()\n",
        "        self.linear1 = nn.Sequential(nn.Linear(163, 326), nn.SELU(), nn.Linear(326, 256), nn.SELU())\n",
        "        self.linear2 = nn.Sequential(nn.Linear(256, 128), nn.SELU(), nn.Linear(128, 64), nn.SELU())\n",
        "        self.dropout = nn.Dropout()\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Combine_model(nn.Module):\n",
        "    def __init__(self,args) -> None:\n",
        "        super(Combine_model,self).__init__()\n",
        "        if args.backbone == \"DinoV2\":\n",
        "            self.model1 = DinoV2(args)\n",
        "        elif args.backbone == \"Resnet18\":\n",
        "            self.model1 = Resnet18(args)\n",
        "        # self.model1 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        # self.model1 = DinoV2(args) #output size [batch,(H/patch_size)*(W/patch_size),768]\n",
        "\n",
        "        self.model2 = MLP()\n",
        "\n",
        "        self.out_fc1 = nn.Sequential(\n",
        "            nn.Linear(128+64,24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24,6)\n",
        "        )\n",
        "        self.out_fc2 = nn.Sequential(\n",
        "            nn.Linear(128+64,24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24,6)\n",
        "        )\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        x = self.model1(x)\n",
        "        y = self.model2(y)\n",
        "        x = torch.cat([x, y], dim = 1)\n",
        "        return self.out_fc1(x), self.out_fc2(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data(args):\n",
        "    # load data\n",
        "    train_df = pd.read_csv(args.train_path)\n",
        "    test_df = pd.read_csv(args.test_path)\n",
        "    train_df['id'] = train_df['id'].map(lambda x: args.base_path + '/train_images/' + str(x)+ \".jpeg\")\n",
        "    test_df['id'] = test_df['id'].map(lambda x: args.base_path + '/test_images/' + str(x)+ \".jpeg\")\n",
        "    args.FEATURE_COLS = test_df.columns[1:].tolist()\n",
        "\n",
        "    # remove outliers\n",
        "    train_df = delete_abnormal_values(train_df, args.label_features+args.sd_features)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def split_dataset(train_df, test_df, args):\n",
        "\n",
        "    label_df = train_df[args.label_features+args.sd_features]\n",
        "    train_df = train_df.drop(columns = args.label_features+args.sd_features)\n",
        "\n",
        "    x_train,x_val,y_train,y_val = train_test_split(train_df, label_df, test_size=0.1)\n",
        "    x_train_images = np.array(x_train['id'])\n",
        "    x_train = x_train.drop(columns = 'id')\n",
        "    x_val_images = np.array(x_val['id'])\n",
        "    x_val = x_val.drop(columns = 'id')\n",
        "    y_train,y_val = np.array(y_train).astype(np.float32), np.array(y_val).astype(np.float32)\n",
        "\n",
        "    return x_train,x_val,y_train,y_val,x_train_images,x_val_images\n",
        "\n",
        "def get_dataloader(args):\n",
        "\n",
        "    train_df, test_df = load_data(args)\n",
        "    x_train,x_val,y_train,y_val,x_train_images,x_val_images = split_dataset(train_df, test_df, args)\n",
        "\n",
        "    scaler = Normalizer()\n",
        "    train_features = scaler.fit_transform(x_train[args.FEATURE_COLS].values).astype(np.float32)\n",
        "    valid_features = scaler.transform(x_val[args.FEATURE_COLS].values).astype(np.float32)\n",
        "\n",
        "    train_labels = y_train[:,:6]\n",
        "    train_labels_aux = y_train[:,6:]\n",
        "    val_labels = y_val[:,:6]\n",
        "    val_labels_aux = y_val[:,6:]\n",
        "\n",
        "    train_features[np.isnan(train_features)] = -1\n",
        "    valid_features[np.isnan(valid_features)] = -1\n",
        "\n",
        "    train_labels[np.isnan(train_labels)] = -1\n",
        "    train_labels_aux[np.isnan(train_labels_aux)] = -1\n",
        "    val_labels[np.isnan(val_labels)] = -1\n",
        "    val_labels_aux[np.isnan(val_labels_aux)] = -1\n",
        "\n",
        "\n",
        "    train_dataset = [(x_train_images[i], train_features[i],train_labels[i], train_labels_aux[i] ) for i in range(len(x_train_images[:data_slice]))]\n",
        "    val_dataset = [(x_val_images[i], valid_features[i],val_labels[i],val_labels_aux[i]) for i in range(len(x_val_images[:data_slice]))]\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset, batch_size=args.BATCH_SIZE , shuffle= True, num_workers = 2)\n",
        "    val_loader = DataLoader(dataset = val_dataset, batch_size=args.BATCH_SIZE , shuffle= False, num_workers = 2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "fU9NBRQgY1TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV2ni7JCQino"
      },
      "outputs": [],
      "source": [
        "def transform(imgs,img_size,type='train',backbone='ResNet'):\n",
        "\n",
        "    if type == 'train':\n",
        "         trans = transforms.Compose([\n",
        "                    transforms.Resize((img_size, img_size)),\n",
        "                    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=(0.45, 0.55), hue=0.1),\n",
        "                    transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    transforms.RandomRotation((-10,10)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "                ])\n",
        "    elif type == 'validate':\n",
        "        trans = transforms.Compose([\n",
        "                transforms.Resize((img_size, img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "            ])\n",
        "\n",
        "    return trans(imgs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "SFQZTIwsbN0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juSAA7D3Qinp"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0EwSIV8Qinp"
      },
      "outputs": [],
      "source": [
        "class R2Loss(nn.Module):\n",
        "    def __init__(self, use_mask=False):\n",
        "        super(R2Loss, self).__init__()\n",
        "        self.use_mask = use_mask\n",
        "\n",
        "    def forward(self,y_pred , y_true):\n",
        "        if self.use_mask:\n",
        "            mask = (y_true != -1)\n",
        "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
        "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
        "        SS_res = torch.sum((y_true - y_pred) ** 2,axis=0)\n",
        "        SS_tot = torch.sum((y_true - torch.mean(y_true, 1, True)) ** 2,axis=0)\n",
        "        r2_loss = SS_res / (SS_tot + 1e-6)\n",
        "\n",
        "        return torch.mean(r2_loss)\n",
        "\n",
        "\n",
        "class MSELoss(nn.Module):\n",
        "    def __init__(self, use_mask=False):\n",
        "        super(MSELoss, self).__init__()\n",
        "        self.use_mask = use_mask\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        if self.use_mask:\n",
        "            mask = (y_true != -1)\n",
        "            y_true = torch.where(mask, y_true, torch.zeros_like(y_true))\n",
        "            y_pred = torch.where(mask, y_pred, torch.zeros_like(y_pred))\n",
        "        mse_loss = torch.mean((y_true - y_pred) ** 2)\n",
        "        return mse_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Test"
      ],
      "metadata": {
        "id": "eG_9CFN4mDZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hvudBjYQinp"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_loader,model, criterion1, criterion2, optimizer, scheduler, device,args):\n",
        "    args.run_type = 'train'\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, data in tqdm(enumerate(train_loader)):\n",
        "        # Unpack data\n",
        "        img_path, inputs, labels, labels_aux = data\n",
        "\n",
        "        # Prepare image paths\n",
        "        # # Prepare inputs and labels\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels_aux = labels_aux.to(device)\n",
        "\n",
        "        # Load and transform images\n",
        "        batch_size = len(img_path)\n",
        "        images = torch.zeros(batch_size, 3, args.img_size, args.img_size, dtype=torch.float32)\n",
        "        for i in range(batch_size):\n",
        "            image = Image.open(img_path[i]).convert(\"RGB\")\n",
        "            images[i] = transform(image,args.img_size,args.run_type,args.backbone)  # Assuming train_transform is defined elsewhere\n",
        "\n",
        "        # Forward pass\n",
        "        images = images.to(device)\n",
        "        output1,output2 = model(images, inputs)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss1 = criterion1[0](output1, labels)\n",
        "        loss2 = criterion2[0](output2,labels_aux)\n",
        "\n",
        "        loss = loss1 + 0.2*loss2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    return avg_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eowMBMXQinq"
      },
      "outputs": [],
      "source": [
        "def evaluate_epoch(test_loader,model,criterion1,criterion2,device,args):\n",
        "    model.eval()\n",
        "    args.run_type = 'validate'\n",
        "    total_loss = 0\n",
        "    total_r2_loss = 0\n",
        "    output = []\n",
        "    total_label = []\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(test_loader)):\n",
        "            # Unpack data\n",
        "            img_path, inputs, labels, labels_aux = data\n",
        "            # Prepare image paths\n",
        "            # # Prepare inputs and labels\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels_aux = labels_aux.to(device)\n",
        "\n",
        "            batch_size = len(img_path)\n",
        "            images = torch.zeros(batch_size, 3, args.img_size, args.img_size, dtype=torch.float32)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                image = Image.open(img_path[i]).convert(\"RGB\")\n",
        "                images[i] = transform(image,args.img_size,args.run_type,args.backbone)   # Assuming train_transform is defined elsewhere\n",
        "\n",
        "            # Forward pass\n",
        "            images = images.to(device)\n",
        "            output1,output2 = model(images, inputs)\n",
        "            output.append(output1)\n",
        "            total_label.append(labels)\n",
        "            loss1 = criterion1[0](output1, labels) + 0.2*criterion2[0](output2,labels_aux)\n",
        "            loss2 = criterion1[0](output1, labels)\n",
        "            total_r2_loss += loss2.item()\n",
        "            total_loss += loss1.item()\n",
        "            total_r2 = criterion1[0](torch.cat(output, dim = 0), torch.cat(total_label, dim = 0))\n",
        "\n",
        "        avg_loss = total_loss/len(test_loader)\n",
        "        avg_r2_loss = total_r2_loss/len(test_loader)\n",
        "    return avg_loss, avg_r2_loss, total_r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT8-n8XoQinr"
      },
      "outputs": [],
      "source": [
        "args.BATCH_SIZE = 128\n",
        "args.patch_size = 14\n",
        "args.backbone = 'DinoV2'\n",
        "args.pretrain_choice = 'frozen'\n",
        "args.decoder = 'Linear'\n",
        "\n",
        "\n",
        "def plot_losses(train_losses, test_losses, args):\n",
        "    losses = [train_losses, test_losses]\n",
        "    point = pd.DataFrame(losses,columns=np.arange(1,args.MAX_EPOCH+1),index=['train','test']).T\n",
        "    ax = sns.lineplot(data=point)\n",
        "    ax.set(xlabel='epoch',ylabel='R2')\n",
        "\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = Combine_model(args).to(device)\n",
        "\n",
        "    summary(mode, (3,128,128))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=args.weight_decay, lr=args.LR)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.MAX_EPOCH, eta_min=0, last_epoch=-1)\n",
        "\n",
        "    criterion1 = [R2Loss(use_mask=False), MSELoss(use_mask=False)]\n",
        "    criterion2 = [R2Loss(use_mask=True), MSELoss(use_mask=True)]\n",
        "\n",
        "    train_loader, val_loader = get_dataloader(args)\n",
        "\n",
        "    best_r2 = - np.inf\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(args.MAX_EPOCH):\n",
        "\n",
        "        train_loss = train_epoch(train_loader, model,criterion1,criterion2,optimizer,scheduler,device,args)\n",
        "        test_loss, test_r2_loss, total_R2 = evaluate_epoch(val_loader,model, criterion1,criterion2, device, args)\n",
        "\n",
        "        best_r2 = max(best_r2, 1 - total_R2)\n",
        "        print(\"Train_loss is: {}, test loss is: {}, test R2 loss is: {}, test R2 is: {}, current best result: {}\"\\\n",
        "            .format(train_loss, test_loss, test_r2_loss, 1 - total_R2, best_r2))\n",
        "\n",
        "        logging.info(\"Epoch %s\", epoch)\n",
        "        logging.info(\"Train loss: %s\", train_loss)\n",
        "        logging.info(\"Test loss: %s\", test_loss)\n",
        "        logging.info(\"Test R2 loss: %s\", test_r2_loss)\n",
        "        logging.info(\"Test R2: %s\", 1 - total_R2)\n",
        "\n",
        "        losses.append([train_loss, test_r2_loss, test_r2_loss, total_R2])\n",
        "\n",
        "        if best_r2 == 1 - total_R2:\n",
        "            torch.save(model, args.output_path + \"/Dino.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3oykJUFQinr"
      },
      "outputs": [],
      "source": [
        "train(args)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nnunet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}